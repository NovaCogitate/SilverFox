{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APEX: OFF\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "\n",
    "import sys\n",
    "import json\n",
    "os.chdir('../')\n",
    "\n",
    "# sys.path.append(\"/home/j622s/Desktop/SilverFox/SilverFox/\")\n",
    "\n",
    "from diffusion_model.trainer_brats import GaussianDiffusion, Trainer\n",
    "from diffusion_model.unet_brats import create_model\n",
    "from datasets.dataset_crosses import RandomCrossDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/j622s/Desktop/Silverfox/SilverFox'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# find the current working folder \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported image size: 128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(results_folder, \u001b[39m\"\u001b[39m\u001b[39mconfig.txt\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(config, f)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m model \u001b[39m=\u001b[39m create_model(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m     image_size\u001b[39m=\u001b[39;49minput_size,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m     num_channels\u001b[39m=\u001b[39;49mnum_channels,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m     num_res_blocks\u001b[39m=\u001b[39;49mnum_res_blocks,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m     channel_mult\u001b[39m=\u001b[39;49mchannel_mult,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=97'>98</a>\u001b[0m     learn_sigma\u001b[39m=\u001b[39;49mlearn_sigma,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=98'>99</a>\u001b[0m     in_channels\u001b[39m=\u001b[39;49min_channels,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m     out_channels\u001b[39m=\u001b[39;49mout_channels,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m     class_cond\u001b[39m=\u001b[39;49mclass_cond,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=101'>102</a>\u001b[0m     use_checkpoint\u001b[39m=\u001b[39;49muse_checkpoint,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m     attention_resolutions\u001b[39m=\u001b[39;49mattention_resolutions,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m     num_heads\u001b[39m=\u001b[39;49mnum_heads,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=104'>105</a>\u001b[0m     num_head_channels\u001b[39m=\u001b[39;49mnum_head_channels,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=105'>106</a>\u001b[0m     num_heads_upsample\u001b[39m=\u001b[39;49mnum_heads_upsample,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=106'>107</a>\u001b[0m     use_scale_shift_norm\u001b[39m=\u001b[39;49muse_scale_shift_norm,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=107'>108</a>\u001b[0m     dropout\u001b[39m=\u001b[39;49mdropout,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=108'>109</a>\u001b[0m     resblock_updown\u001b[39m=\u001b[39;49mresblock_updown,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=109'>110</a>\u001b[0m     use_fp16\u001b[39m=\u001b[39;49muse_fp16,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=110'>111</a>\u001b[0m     use_new_attention_order\u001b[39m=\u001b[39;49muse_new_attention_order,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=111'>112</a>\u001b[0m )\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=113'>114</a>\u001b[0m diffusion \u001b[39m=\u001b[39m GaussianDiffusion(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=114'>115</a>\u001b[0m     denoise_fn\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=115'>116</a>\u001b[0m     image_size\u001b[39m=\u001b[39minput_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=124'>125</a>\u001b[0m     lambda_bce\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=125'>126</a>\u001b[0m )\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Be040-serv003/home/j622s/Desktop/Silverfox/SilverFox/exploration/exploring_the_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=127'>128</a>\u001b[0m dataset \u001b[39m=\u001b[39m RandomCrossDataset(size\u001b[39m=\u001b[39m(input_size, input_size, depth_size), half\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Silverfox/SilverFox/diffusion_model/unet_brats.py:322\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(image_size, num_channels, num_res_blocks, channel_mult, learn_sigma, class_cond, use_checkpoint, attention_resolutions, num_heads, conv_resample, dims, num_classes, num_head_channels, num_heads_upsample, use_scale_shift_norm, dropout, resblock_updown, use_fp16, use_new_attention_order, in_channels, out_channels)\u001b[0m\n\u001b[1;32m    320\u001b[0m         channel_mult \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    321\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsupported image size: \u001b[39m\u001b[39m{\u001b[39;00mimage_size\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     channel_mult \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mint\u001b[39m(ch_mult) \u001b[39mfor\u001b[39;00m ch_mult \u001b[39min\u001b[39;00m channel_mult\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported image size: 128"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# configuration of data\n",
    "input_size = 128  # the size of image\n",
    "depth_size = 128  # the size of classes\n",
    "\n",
    "\n",
    "# configuration of training\n",
    "batchsize = 64\n",
    "epochs = 20000\n",
    "save_and_sample_every = 100\n",
    "resume_weight = \"\"\n",
    "train_lr = 5e-3\n",
    "step_start_ema = 2000\n",
    "gradient_accumulate_every = 1\n",
    "update_ema_every = 10\n",
    "ema_decay = 0.995\n",
    "\n",
    "# configuration of network\n",
    "num_channels = 32\n",
    "num_res_blocks = 2\n",
    "num_heads = 1\n",
    "num_head_channels = -1\n",
    "num_heads_upsample = -1\n",
    "dropout = 0.05\n",
    "conv_resample = True\n",
    "dims = 3\n",
    "num_classes = None\n",
    "\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "\n",
    "channel_mult = \"\"\n",
    "learn_sigma = False\n",
    "class_cond = False\n",
    "use_checkpoint = False\n",
    "attention_resolutions = \"8\"\n",
    "use_scale_shift_norm = False\n",
    "resblock_updown = True\n",
    "use_fp16 = False\n",
    "use_new_attention_order = True\n",
    "\n",
    "# configuration of diffusion process\n",
    "timesteps = 250\n",
    "\n",
    "data_folder = \"\"\n",
    "results_folder = \"./results_3D\"\n",
    "\n",
    "# the configs above\n",
    "config = {\n",
    "    \"batchsize\": batchsize,\n",
    "    \"epochs\": epochs,\n",
    "    \"save_and_sample_every\": save_and_sample_every,\n",
    "    \"resume_weight\": resume_weight,\n",
    "    \"train_lr\": train_lr,\n",
    "    \"step_start_ema\": step_start_ema,\n",
    "    \"gradient_accumulate_every\": gradient_accumulate_every,\n",
    "    \"update_ema_every\": update_ema_every,\n",
    "    \"ema_decay\": ema_decay,\n",
    "    \"num_channels\": num_channels,\n",
    "    \"num_res_blocks\": num_res_blocks,\n",
    "    \"num_heads\": num_heads,\n",
    "    \"num_head_channels\": num_head_channels,\n",
    "    \"num_heads_upsample\": num_heads_upsample,\n",
    "    \"dropout\": dropout,\n",
    "    \"conv_resample\": conv_resample,\n",
    "    \"dims\": dims,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"in_channels\": in_channels,\n",
    "    \"out_channels\": out_channels,\n",
    "    \"channel_mult\": channel_mult,\n",
    "    \"learn_sigma\": learn_sigma,\n",
    "    \"class_cond\": class_cond,\n",
    "    \"use_checkpoint\": use_checkpoint,\n",
    "    \"attention_resolutions\": attention_resolutions,\n",
    "    \"use_scale_shift_norm\": use_scale_shift_norm,\n",
    "    \"resblock_updown\": resblock_updown,\n",
    "    \"use_fp16\": use_fp16,\n",
    "    \"use_new_attention_order\": use_new_attention_order,\n",
    "    \"timesteps\": timesteps,\n",
    "    \"input_size\": input_size,\n",
    "    \"depth_size\": depth_size,\n",
    "}\n",
    "\n",
    "# save the config\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "with open(os.path.join(results_folder, \"config.txt\"), \"w\") as f:\n",
    "    json.dump(config, f)\n",
    "\n",
    "model = create_model(\n",
    "    image_size=input_size,\n",
    "    num_channels=num_channels,\n",
    "    num_res_blocks=num_res_blocks,\n",
    "    channel_mult=channel_mult,\n",
    "    learn_sigma=learn_sigma,\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    class_cond=class_cond,\n",
    "    use_checkpoint=use_checkpoint,\n",
    "    attention_resolutions=attention_resolutions,\n",
    "    num_heads=num_heads,\n",
    "    num_head_channels=num_head_channels,\n",
    "    num_heads_upsample=num_heads_upsample,\n",
    "    use_scale_shift_norm=use_scale_shift_norm,\n",
    "    dropout=dropout,\n",
    "    resblock_updown=resblock_updown,\n",
    "    use_fp16=use_fp16,\n",
    "    use_new_attention_order=use_new_attention_order,\n",
    ").cuda()\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    denoise_fn=model,\n",
    "    image_size=input_size,\n",
    "    depth_size=depth_size,\n",
    "    channels=in_channels,\n",
    "    timesteps=timesteps,\n",
    "    loss_type=\"l1\",\n",
    "    betas=None,\n",
    "    with_condition=class_cond,\n",
    "    with_pairwised=False,\n",
    "    apply_bce=False,\n",
    "    lambda_bce=0.0,\n",
    ").cuda()\n",
    "\n",
    "dataset = RandomCrossDataset(size=(input_size, input_size, depth_size), half=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    diffusion_model=diffusion,\n",
    "    dataset=dataset,\n",
    "    ema_decay=ema_decay,\n",
    "    depth_size=depth_size,\n",
    "    train_batch_size=batchsize,\n",
    "    train_lr=train_lr,\n",
    "    train_num_steps=epochs,\n",
    "    gradient_accumulate_every=gradient_accumulate_every,\n",
    "    fp16=use_fp16,\n",
    "    step_start_ema=step_start_ema,\n",
    "    update_ema_every=update_ema_every,\n",
    "    save_and_sample_every=save_and_sample_every,\n",
    "    results_folder=results_folder,\n",
    "    with_condition=class_cond,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
